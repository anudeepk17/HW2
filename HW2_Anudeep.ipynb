{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7b21zza1Ro8i",
        "outputId": "3c5934e8-49db-449f-f845-2a22a3e98b41"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def XOR (a, b):\n",
        "    if a != b:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "x = [0,0,1,1]\n",
        "y = [0,1,0,1]\n",
        "for i in range(4):\n",
        "  a=XOR(x[i],y[i])\n",
        "  if a:\n",
        "    col='magenta'\n",
        "  else:\n",
        "    col='black'\n",
        "  plt.scatter(x[i],y[i],c=col)\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6E0ltQn-fM3"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VspVdxs9UM67"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import operator\n",
        "import json\n",
        "def entropy(df,y):\n",
        "        ent = 0\n",
        "        for target in np.unique(df[y]):\n",
        "            pr = df[y].value_counts()[target] / len(df[y])\n",
        "            ent += -pr * np.log2(pr)\n",
        "\n",
        "        return ent\n",
        "\n",
        "def entropycalc( df,S , entropy_parent,Y):\n",
        "        thresh = None\n",
        "        info_gain_ratio = 0\n",
        "        #print(\"\\n Feature: {}\".format(S))\n",
        "\n",
        "        for val in np.unique(df[S]):\n",
        "            cur_entropy = 0\n",
        "            cutoff = val\n",
        "            SgivenY = 0\n",
        "            for operation in [operator.lt, operator.ge]:\n",
        "                entropy_S = 0\n",
        "                numOfFeat = 0\n",
        "                for cat in np.unique(df[Y]):\n",
        "                    numY = len(df[S][operation(df[S], cutoff)][df[Y] == cat])\n",
        "                    numOfFeat = len(df[S][operation(df[S], cutoff)])\n",
        "\n",
        "                    if numOfFeat == 0:\n",
        "                        continue\n",
        "                    probYgivenFeat = numY / numOfFeat\n",
        "                    if probYgivenFeat > 0:\n",
        "                        entropy_S += -probYgivenFeat * np.log2(probYgivenFeat)\n",
        "\n",
        "                probFeat = numOfFeat / len(df)\n",
        "                cur_entropy += probFeat * entropy_S\n",
        "                if probFeat > 0:\n",
        "                    SgivenY += -probFeat * np.log2(probFeat)\n",
        "            if SgivenY == 0:\n",
        "                print(\"\\n Mutual Information: {}\".format(entropy_parent - cur_entropy))\n",
        "                print(\"If Split at: {}\".format(cutoff))\n",
        "                continue\n",
        "            cur_info_gain_ratio = (entropy_parent - cur_entropy) / SgivenY\n",
        "            cur_info_gain = (entropy_parent - cur_entropy)\n",
        "            print(\"\\n Info Gain ratio: {}\".format(cur_info_gain_ratio))\n",
        "            print(\"\\n Info Gain: {}\".format(cur_info_gain))\n",
        "            print(\"If Split at: {}\".format(cutoff))\n",
        "\n",
        "                \n",
        "            if cur_info_gain_ratio > info_gain_ratio:\n",
        "                info_gain_ratio = cur_info_gain_ratio\n",
        "                thresh = cutoff\n",
        "\n",
        "        return info_gain_ratio, thresh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxCNabIJdvoJ"
      },
      "outputs": [],
      "source": [
        "df= pd.read_table('Druns.txt', sep=\" \", header=None, names=[\"X1\", \"X2\", \"Y\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMEdDUTK-jDn",
        "outputId": "ec90c6a4-8608-4aa3-bf36-cbc70e602587"
      },
      "outputs": [],
      "source": [
        "entropycalc(df,'X1',entropy(df,'Y'),'Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWH40Vw-by2U",
        "outputId": "906335a1-0cf4-4f62-f110-3cae64933859"
      },
      "outputs": [],
      "source": [
        "entropycalc(df,'X2',entropy(df,'Y'),'Y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1tkaIX6-mGy"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkuBR8bBlKyf"
      },
      "outputs": [],
      "source": [
        "df1= pd.read_table('D3leaves.txt', sep=\" \", header=None, names=[\"X1\", \"X2\", \"Y\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X50QRH7xmxv1"
      },
      "outputs": [],
      "source": [
        "ig1,th1=entropycalc(df,'X1',entropy(df1,'Y'),'Y')\n",
        "ig2,th2=entropycalc(df,'X2',entropy(df1,'Y'),'Y')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYPVXMk9AD63",
        "outputId": "68fd0184-d3d4-4937-9149-d2ecef4578ff"
      },
      "outputs": [],
      "source": [
        "Node={ig1:'X1',ig2:'X2'}\n",
        "igmax,Threshold=max(ig1,ig2),max(th1,th2)\n",
        "print(\"Node:\",Node[igmax],\"\\tThreshold:\",Threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSsQPgTCKFzi"
      },
      "source": [
        "Let us define a class that incorporates the above code and makes a tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PZ7jSLWAMHg"
      },
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self):\n",
        "        self.tree = None\n",
        "        self.features = list\n",
        "        self.XTrain = np.array\n",
        "        self.yTrain = np.array\n",
        "        self.num_feats = int\n",
        "        self.train_size = int\n",
        "        self.nodes = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.XTrain = X\n",
        "        self.yTrain = y\n",
        "        self.features = list(X.columns)\n",
        "        self.train_size = X.shape[0]\n",
        "        self.num_feats = X.shape[1]\n",
        "\n",
        "        df = X.copy()\n",
        "        df['category'] = y.copy()\n",
        "\n",
        "        self.tree = self.make_subtree(df)\n",
        "        s = str(self.tree)\n",
        "        s = s.replace(\"\\'\", \"\\\"\")\n",
        "        json_object = json.loads(s)\n",
        "        print(json.dumps(json_object, indent=2))\n",
        "\n",
        "    def make_subtree(self, df, tree=None):\n",
        "        feature, cutoff = self.find_best_split(df)\n",
        "        categories, count = np.unique(df['category'], return_counts=True)\n",
        "        if tree is None:\n",
        "            tree = {feature: {}}\n",
        "        if cutoff == None:\n",
        "          tree[feature]['>=' + str(-2.5) + ' then'] = 1\n",
        "          return tree\n",
        "        \n",
        "        self.nodes +=1  \n",
        "\n",
        "        # Left Child\n",
        "        new_df = self.splitData(df, feature, cutoff, operator.ge)\n",
        "        categories, count = np.unique(new_df['category'], return_counts=True)\n",
        "\n",
        "        if len(count) == 1:  # all are same category\n",
        "            tree[feature]['>=' + str(cutoff) + ' then'] = categories[0]\n",
        "        else:\n",
        "            tree[feature]['>=' + str(cutoff) + ' then'] = self.make_subtree(new_df)\n",
        "\n",
        "        # Right Child\n",
        "        new_df = self.splitData(df, feature, cutoff, operator.lt)\n",
        "        categories, count = np.unique(new_df['category'], return_counts=True)\n",
        "\n",
        "        if len(count) == 1:  # all are same category\n",
        "            tree[feature]['else ' + '<' + str(cutoff)] = categories[0]\n",
        "        else:\n",
        "            tree[feature]['else ' + '<' + str(cutoff)] = self.make_subtree(new_df)\n",
        "\n",
        "        return tree\n",
        "    def splitData(self, df, feature, decide, operation):\n",
        "        return df[operation(df[feature], decide)].reset_index(drop=True)\n",
        "    def entropy(self,df):\n",
        "        ent = 0\n",
        "        for target in np.unique(df['category']):\n",
        "            pr = df['category'].value_counts()[target] / len(df['category'])\n",
        "            ent += -pr * np.log2(pr)\n",
        "\n",
        "        return ent\n",
        "\n",
        "    def entropycalc( self,df,S , entropy_parent):\n",
        "        thresh = None\n",
        "        info_gain_ratio = 0\n",
        "        #print(\"\\n Feature: {}\".format(S))\n",
        "\n",
        "        for val in np.unique(df[S]):\n",
        "            cur_entropy = 0\n",
        "            cutoff = val\n",
        "            SgivenY = 0\n",
        "            for operation in [operator.lt, operator.ge]:\n",
        "                entropy_S = 0\n",
        "                numOfFeat = 0\n",
        "                for cat in np.unique(df['category']):\n",
        "                    numY = len(df[S][operation(df[S], cutoff)][df['category'] == cat])\n",
        "                    numOfFeat = len(df[S][operation(df[S], cutoff)])\n",
        "\n",
        "                    if numOfFeat == 0:\n",
        "                        continue\n",
        "                    probYgivenFeat = numY / numOfFeat\n",
        "                    if probYgivenFeat > 0:\n",
        "                        entropy_S += -probYgivenFeat * np.log2(probYgivenFeat)\n",
        "\n",
        "                probFeat = numOfFeat / len(df)\n",
        "                cur_entropy += probFeat * entropy_S\n",
        "                if probFeat > 0:\n",
        "                    SgivenY += -probFeat * np.log2(probFeat)\n",
        "            if SgivenY == 0:\n",
        "                #print(\"\\n Mutual Information: {}\".format(entropy_parent - cur_entropy))\n",
        "                #print(\"If Split at: {}\".format(cutoff))\n",
        "                continue\n",
        "            cur_info_gain_ratio = (entropy_parent - cur_entropy) / SgivenY\n",
        "            cur_info_gain = (entropy_parent - cur_entropy)\n",
        "            #print(\"\\n Info Gain ratio: {}\".format(cur_info_gain_ratio))\n",
        "            #print(\"\\n Info Gain: {}\".format(cur_info_gain))\n",
        "            #print(\"If Split at: {}\".format(cutoff))\n",
        "\n",
        "                \n",
        "            if cur_info_gain_ratio > info_gain_ratio:\n",
        "                info_gain_ratio = cur_info_gain_ratio\n",
        "                thresh = cutoff\n",
        "        return info_gain_ratio, thresh\n",
        "    def find_best_split(self, df):\n",
        "          igr = []\n",
        "          thresholds = []\n",
        "\n",
        "          for feature in list(df.columns[:-1]):\n",
        "              entropy_parent = self.entropy(df)  # H(T)\n",
        "              info_gain_ratio, threshold = self.entropycalc(df, feature, entropy_parent)  # H(T|a)\n",
        "\n",
        "              igr.append(info_gain_ratio)\n",
        "              thresholds.append(threshold)\n",
        "         \n",
        "          #print(thresholds)\n",
        "          #print(igr) \n",
        "          return df.columns[:-1][np.argmax(igr)], thresholds[np.argmax(igr)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN7105LlDF0p",
        "outputId": "8e9221f1-3767-4859-caa0-498d430f0ca2"
      },
      "outputs": [],
      "source": [
        "X, y = df1.drop([df1.columns[-1]], axis=1), df1[df1.columns[-1]]\n",
        "dt_clf1 = DecisionTree()\n",
        "dt_clf1.fit(X, y)\n",
        "print(dt_clf1.nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM82BgLHNb8I"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Co5wjk7EJv-",
        "outputId": "21e42a4b-9406-4697-f3df-644e8d31764a"
      },
      "outputs": [],
      "source": [
        "df2= pd.read_table('D1.txt', sep=\" \", header=None, names=[\"X1\", \"X2\", \"Y\"])\n",
        "X, y = df2.drop([df2.columns[-1]], axis=1), df2[df2.columns[-1]]\n",
        "dt_clf2 = DecisionTree()\n",
        "dt_clf2.fit(X, y)\n",
        "print(dt_clf2.nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7WmjtQeYPMN"
      },
      "source": [
        "### Question 5c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQCWrRqaVl79",
        "outputId": "ee48c3f8-5100-4d19-f68a-32fb1abe2a06"
      },
      "outputs": [],
      "source": [
        "df3= pd.read_table('D2.txt', sep=\" \", header=None, names=[\"X1\", \"X2\", \"Y\"])\n",
        "X, y = df3.drop([df3.columns[-1]], axis=1), df3[df3.columns[-1]]\n",
        "dt_clf3 = DecisionTree()\n",
        "dt_clf3.fit(X, y)\n",
        "print(dt_clf3.nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MJjmj1sb3fQ"
      },
      "source": [
        "#Question 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "HJd5HONXYVCB",
        "outputId": "376be7bd-4e7b-4d37-f9a2-9939dfd4bbab"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df2['X1'], df2['X2'], c=df2['Y'])\n",
        "plt.show()\n",
        "plt.scatter(df3['X1'], df3['X2'], c=df3['Y'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT3O-P3xhE_B"
      },
      "source": [
        "To test the decision tree we create a variable with 10000 points and use the Decision tree class object to predict the classes using these test points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6o5w2CmcXSH"
      },
      "outputs": [],
      "source": [
        "Xtest=pd.DataFrame(np.random.uniform(0,1,size=(10000,2)), columns=list(['X1','X2']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fFY5ypQjI9f"
      },
      "source": [
        "Below we create a prediction function that takes in the class and predicts the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzvNs4UqfJKr"
      },
      "outputs": [],
      "source": [
        "def predict(X,dt_clf):\n",
        "  results = []\n",
        "  #Create a dictionary with index and value as the values of columns of input dataset\n",
        "  coldict = {key: i for i, key in enumerate(list(X.columns))}\n",
        "  #Calls the prediction columnwise\n",
        "  for i in range(len(X)):\n",
        "      results.append(predict_X(coldict, X.iloc[i], dt_clf.tree))\n",
        "\n",
        "  return np.array(results)\n",
        "\n",
        "def predict_X(coldict, x, tree):\n",
        "  for node in tree.keys():\n",
        "      val = x[node]\n",
        "      cutoff = str(list(tree[node].keys())[0]).split('>=')[1].split(' ')[0]\n",
        "\n",
        "      if val >= float(cutoff):  # Left Child\n",
        "          tree = tree[node]['>=' + cutoff + ' then']\n",
        "      else:  # Right Child\n",
        "          tree = tree[node]['else ' + '<' + cutoff]\n",
        "\n",
        "      prediction = str\n",
        "\n",
        "      if type(tree) is dict:\n",
        "          prediction = predict_X(coldict, x, tree)\n",
        "      else:\n",
        "          predict = tree\n",
        "          return predict\n",
        "\n",
        "  return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "GPUI7xMgcf2B",
        "outputId": "9f268a36-fa69-4afd-9623-6834c3d8468e"
      },
      "outputs": [],
      "source": [
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf2))\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf3))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jr3GDco2TOo"
      },
      "source": [
        "#Question 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_b9WuotchBB"
      },
      "outputs": [],
      "source": [
        "def error_score(ytrue, ypred):\n",
        "    return round(float(sum(ypred != ytrue)) / float(len(ytrue)) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dDjudnYu7-mU",
        "outputId": "c247bb1d-6051-4c45-c75c-23a114ce2835"
      },
      "outputs": [],
      "source": [
        "data = pd.read_table('Dbig.txt', sep=\" \", header=None, names=[\"X1\", \"X2\", \"Y\"])\n",
        "Xtest=pd.DataFrame(np.random.uniform(-1.5,1.5,size=(2000,2)), columns=list(['X1','X2']))\n",
        "# Split Features and target\n",
        "X, y = data.drop([data.columns[-1]], axis=1), data[data.columns[-1]]\n",
        "plt.scatter(data['X1'], data['X2'], c=data['Y'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yUSDHuso8WJq",
        "outputId": "d5f00871-b2ac-487d-d45c-8fe5c64816d2"
      },
      "outputs": [],
      "source": [
        "XAppend=[]\n",
        "train=data.sample(frac=0.8192, random_state=0)\n",
        "test=data.drop(train.index) \n",
        "\n",
        "\n",
        "train32 = train.iloc[0:32,:]\n",
        "\n",
        "X, y = train32.drop([train32.columns[-1]], axis=1), train32[train32.columns[-1]]\n",
        "print(len(train32))\n",
        "dt_clf = DecisionTree()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E32 = error_score(y, predict(X,dt_clf))\n",
        "print(\"\\nTest Error: {}\".format(E32))\n",
        "XAppend.append(dt_clf.nodes)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train32['X1'], train32['X2'], c=train32['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train32['X1'], train32['X2'], c=train32['Y'])\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf))\n",
        "plt.show()\n",
        "\n",
        "train128 = train.iloc[32:160,:]\n",
        "print(len(train128))\n",
        "X, y = train128.drop([train128.columns[-1]], axis=1), train128[train128.columns[-1]]\n",
        "dt_clf = DecisionTree()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E128 = error_score(y, predict(X,dt_clf))\n",
        "print(\"\\nTest Error: {}\".format(E128))\n",
        "XAppend.append(dt_clf.nodes)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train128['X1'], train128['X2'], c=train128['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train128['X1'], train128['X2'], c=train128['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf))\n",
        "plt.show()\n",
        "\n",
        "train512 = train.iloc[160:672,:]\n",
        "print(len(train512))\n",
        "X, y = train512.drop([train512.columns[-1]], axis=1), train512[train512.columns[-1]]\n",
        "dt_clf = DecisionTree()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E512 = error_score(y, predict(X,dt_clf))\n",
        "print(\"\\nTest Error: {}\".format(E512))\n",
        "XAppend.append(dt_clf.nodes)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train512['X1'], train512['X2'], c=train512['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train512['X1'], train512['X2'], c=train512['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf))\n",
        "plt.show()\n",
        "\n",
        "train2048 = train.iloc[672:2720,:]\n",
        "print(len(train2048))\n",
        "X, y = train2048.drop([train2048.columns[-1]], axis=1), train2048[train2048.columns[-1]]\n",
        "dt_clf = DecisionTree()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E2048 = error_score(y, predict(X,dt_clf))\n",
        "print(\"\\nTest Error: {}\".format(E2048))\n",
        "XAppend.append(dt_clf.nodes)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train2048['X1'], train2048['X2'], c=train2048['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train2048['X1'], train2048['X2'], c=train2048['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf))\n",
        "plt.show()\n",
        "\n",
        "print(len(train))\n",
        "X, y = train.drop([train.columns[-1]], axis=1), train[train.columns[-1]]\n",
        "dt_clf = DecisionTree()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E8192 = error_score(y, predict(X,dt_clf))\n",
        "print(\"\\nTest Error: {}\".format(E8192))\n",
        "XAppend.append(dt_clf.nodes)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train['X1'], train['X2'], train['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train['X1'], train['X2'], c=train['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=predict(Xtest,dt_clf))\n",
        "plt.show()\n",
        "\n",
        "XAppend = np.array(XAppend)\n",
        "Ycord = np.array([E32, E128, E512, E2048, E8192])\n",
        "print(XAppend)\n",
        "\n",
        "plt.plot(XAppend, Ycord)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhObKkF4NUtp"
      },
      "source": [
        "#Question 3 \n",
        "##SKLEARN\n",
        "We reuse the above code just replacing our decision tree with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTot6WbT_qOE"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mwaQMCBrNw-w",
        "outputId": "b2ddf23f-9e48-4f32-a4cb-3e89dade53a2"
      },
      "outputs": [],
      "source": [
        "XAppend=[]\n",
        "train=data.sample(frac=0.8192, random_state=0)\n",
        "test=data.drop(train.index) \n",
        "\n",
        "\n",
        "train32 = train.iloc[0:32,:]\n",
        "\n",
        "X, y = train32.drop([train32.columns[-1]], axis=1), train32[train32.columns[-1]]\n",
        "print(len(train32))\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E32 = error_score(y, dt_clf.predict(X))\n",
        "print(\"\\nTest Error: {}\".format(E32))\n",
        "XAppend.append(dt_clf.tree_.node_count)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train32['X1'], train32['X2'], c=train32['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train32['X1'], train32['X2'], c=train32['Y'])\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=dt_clf.predict(Xtest))\n",
        "plt.show()\n",
        "\n",
        "train128 = train.iloc[32:160,:]\n",
        "print(len(train128))\n",
        "X, y = train128.drop([train128.columns[-1]], axis=1), train128[train128.columns[-1]]\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E128 = error_score(y, dt_clf.predict(X))\n",
        "print(\"\\nTest Error: {}\".format(E128))\n",
        "XAppend.append(dt_clf.tree_.node_count)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train128['X1'], train128['X2'], c=train128['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train128['X1'], train128['X2'], c=train128['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=dt_clf.predict(Xtest))\n",
        "plt.show()\n",
        "\n",
        "train512 = train.iloc[160:672,:]\n",
        "print(len(train512))\n",
        "X, y = train512.drop([train512.columns[-1]], axis=1), train512[train512.columns[-1]]\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E512 = error_score(y, dt_clf.predict(X))\n",
        "print(\"\\nTest Error: {}\".format(E512))\n",
        "XAppend.append(dt_clf.tree_.node_count)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train512['X1'], train512['X2'], c=train512['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train512['X1'], train512['X2'], c=train512['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=dt_clf.predict(Xtest))\n",
        "plt.show()\n",
        "\n",
        "train2048 = train.iloc[672:2720,:]\n",
        "print(len(train2048))\n",
        "X, y = train2048.drop([train2048.columns[-1]], axis=1), train2048[train2048.columns[-1]]\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E2048 = error_score(y, dt_clf.predict(X))\n",
        "print(\"\\nTest Error: {}\".format(E2048))\n",
        "XAppend.append(dt_clf.tree_.node_count)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train2048['X1'], train2048['X2'], c=train2048['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train2048['X1'], train2048['X2'], c=train2048['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=dt_clf.predict(Xtest))\n",
        "plt.show()\n",
        "\n",
        "print(len(train))\n",
        "X, y = train.drop([train.columns[-1]], axis=1), train[train.columns[-1]]\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X, y)\n",
        "X, y = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "E8192 = error_score(y, dt_clf.predict(X))\n",
        "print(\"\\nTest Error: {}\".format(E8192))\n",
        "XAppend.append(dt_clf.tree_.node_count)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(train['X1'], train['X2'], train['Y'])\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('Y')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(train['X1'], train['X2'], c=train['Y'])\n",
        "plt.show()\n",
        "plt.scatter(Xtest['X1'], Xtest['X2'], c=dt_clf.predict(Xtest))\n",
        "plt.show()\n",
        "\n",
        "XAppend = np.array(XAppend)\n",
        "Ycord = np.array([E32, E128, E512, E2048, E8192])\n",
        "print(XAppend)\n",
        "\n",
        "plt.plot(XAppend, Ycord)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWdTwXUz0mx-"
      },
      "source": [
        "# Question 4\n",
        "Lagranges Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DzID9ROa4JU"
      },
      "outputs": [],
      "source": [
        "from numpy.polynomial.polynomial import Polynomial\n",
        "from scipy.interpolate import lagrange\n",
        "def randomSel(Xtrain,Ytrain,n):\n",
        "  index = np.random.choice(Xtrain.shape[0], n, replace=False) \n",
        "  x_random = Xtrain[index]\n",
        "  y_random = Ytrain[index]\n",
        "  return x_random,y_random\n",
        "\n",
        "def plotPred(poly,Xtrain,Ytrain):\n",
        "  ypred16=Polynomial(poly.coef[::-1])(Xtrain)\n",
        "  plt.scatter(Xtrain, Ytrain, label='data')\n",
        "  plt.scatter(Xtrain, ypred16, label='Polynomial trained')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  return ypred16\n",
        "\n",
        "def mse(ypred16,Ytrain):\n",
        "  err16=0\n",
        "  for i in range(len(ypred16)):\n",
        "    err16+=(ypred16[i]-Ytrain[i])**2\n",
        "  mser=np.sqrt(err16/len(ypred16))\n",
        "  print(\"Mean squared Error on datapoints :\",mser)\n",
        "  return mser\n",
        "\n",
        "Xtrain = np.random.uniform(0, 2*math.pi, size=100)\n",
        "Ytrain = np.sin(Xtrain)\n",
        "Xtest = np.random.uniform(0, 2*math.pi, size=100)\n",
        "Ytest = np.sin(Xtest)\n",
        "x_random,y_random=randomSel(Xtrain,Ytrain,16)\n",
        "poly = lagrange((x_random),(y_random))\n",
        "poly100= lagrange((Xtrain),(Ytrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isXs_icj2veZ"
      },
      "source": [
        "Training on 100 and 16 random training points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQgX65X2060"
      },
      "source": [
        "Testing on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Cuhe01Ah0TcO",
        "outputId": "deb5d082-e087-4ecd-d6bd-6cc52dee09ec"
      },
      "outputs": [],
      "source": [
        "ypred16=plotPred(poly,Xtrain,Ytrain)\n",
        "ypred100=plotPred(poly100,Xtrain,Ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaC4ZGu63DoJ"
      },
      "source": [
        "MSE on training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U436BUnApXa",
        "outputId": "ead0ee43-960a-4cf7-9f1d-786cd393a449"
      },
      "outputs": [],
      "source": [
        "mse(ypred16,Ytrain)\n",
        "mse(ypred100,Ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YozVG2l3S2j"
      },
      "source": [
        "Testing on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "N9_yVDaT2SKJ",
        "outputId": "c8ac28ab-57f9-49bf-b36f-e5d7fd4551be"
      },
      "outputs": [],
      "source": [
        "ypred16=plotPred(poly,Xtest,Ytest)\n",
        "ypred100=plotPred(poly100,Xtest,Ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNYqMitf2mOc",
        "outputId": "bee590f3-e0f7-404b-ceaf-c23b956e4a89"
      },
      "outputs": [],
      "source": [
        "mse(ypred16,Ytest)\n",
        "mse(ypred100,Ytest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgJCcBkz0t_r"
      },
      "source": [
        "Adding Guassian Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1y4gs-xux6F"
      },
      "outputs": [],
      "source": [
        "def noiseadd(sigma):\n",
        "  noise = np.random.normal(0, sigma, [100])\n",
        "  XNoise=noise+Xtrain\n",
        "  plt.scatter(XNoise, Ytrain, label='Noisy Data')\n",
        "  plt.show()\n",
        "  x_noise,y_random=randomSel(XNoise,Ytrain,16)\n",
        "  poly = lagrange((x_noise),(y_random))\n",
        "  ypredtrain=plotPred(poly,x_noise,y_random)\n",
        "  ypredtest=plotPred(poly,Xtest,Ytest)\n",
        "  print(\"===Error for training data====\")\n",
        "  mse(ypredtrain,y_random)\n",
        "  print(\"===Error for Full data====\")\n",
        "  mse(ypredtest,Ytest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "citmlOY84OLs",
        "outputId": "9d9196f7-c3ad-49c7-d2e8-a391e31ff6b2"
      },
      "outputs": [],
      "source": [
        "noiseadd(0.01)\n",
        "noiseadd(0.1)\n",
        "noiseadd(0.5)\n",
        "noiseadd(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfBfgFihD1sU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
